{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from LangGraphAgent import LangGraphAgentWorkflow\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# from langfuse import Langfuse\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "from pydantic import BaseModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# # financial scanner\n",
    "client_chat = AzureOpenAI(\n",
    "    azure_endpoint=\"https://data-ai-labs-poc.openai.azure.com/\",\n",
    "    api_key=os.getenv(\"AZURE2\"),\n",
    "    api_version=\"2024-08-01-preview\"\n",
    ")\n",
    "\n",
    "# langfuse = Langfuse(\n",
    "#   secret_key=os.getenv('LANGFUSE_SECRET_KEY'),\n",
    "#   public_key=os.getenv('LANGFUSE_PUBLIC_KEY'),\n",
    "#   host=os.getenv('LANGFUSE_HOST')\n",
    "# )\n",
    "\n",
    "chat_deployment = \"docs-dev-struct-4o\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseSO(BaseModel):\n",
    "    ingredients: str\n",
    "    url: str \n",
    "    explanation: str\n",
    "    \n",
    "generator_prompt = f'''\n",
    "    You are a product scanner.\n",
    "'''\n",
    "\n",
    "input_text = f'''\n",
    "    What's in the ingredients for Chex Honey Nut Gluten Free Cereal in the US? \n",
    "    - Use your TavilySearchResults() tool and scrape information directly off of urls. \n",
    "    - Once the answer has been provided, don't use your tool and route to the \"formatter_agent\" agent. \n",
    "'''\n",
    "\n",
    "\n",
    "input_dict = {\n",
    "        \"generator_pydantic_class\":ResponseSO,\n",
    "        \"generator_prompt\":generator_prompt,\n",
    "        \"input_text\": input_text\n",
    "}\n",
    "agent = LangGraphAgentWorkflow(input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:LangGraphAgent:Agent received messages: ['\\n    You are a product scanner.\\n\\n\\n', '\\n    What\\'s in the ingredients for Chex Honey Nut Gluten Free Cereal in the US? \\n    - Use your TavilySearchResults() tool and scrape information directly off of urls. \\n    - Once the answer has been provided, don\\'t use your tool and route to the \"formatter_agent\" agent. \\n']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://data-ai-labs-poc.openai.azure.com/openai/deployments/docs-dev-struct-4o/chat/completions?api-version=2024-08-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:LangGraphAgent:Agent response: content='' additional_kwargs={'tool_calls': [{'id': 'call_ITVcoOljrgFIclxFA0WR3pvv', 'function': {'arguments': '{\"query\":\"Chex Honey Nut Gluten Free Cereal ingredients\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 198, 'total_tokens': 224, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f3927aa00d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}} id='run-0a2278f0-47a8-48d7-9644-375541f8a18c-0' tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Chex Honey Nut Gluten Free Cereal ingredients'}, 'id': 'call_ITVcoOljrgFIclxFA0WR3pvv', 'type': 'tool_call'}] usage_metadata={'input_tokens': 198, 'output_tokens': 26, 'total_tokens': 224, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Last message is not an AIMessage",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39minitialize_model(tools)\n\u001b[1;32m      4\u001b[0m app \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mcreate_workflow(agent\u001b[38;5;241m.\u001b[39mshould_continue, agent\u001b[38;5;241m.\u001b[39mcall_model)\n\u001b[0;32m----> 5\u001b[0m final_output \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research/langgraph_agent_framework/LangGraphAgent.py:391\u001b[0m, in \u001b[0;36mLangGraphAgentWorkflow.run_agent\u001b[0;34m(self, app)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03mRuns the agent with a specific query and returns the final output from the agent.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    str: The content of the last message in the final state.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Use the Runnable to process the query\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m final_state \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_text\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigurable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthread_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_state \u001b[38;5;241m=\u001b[39m final_state\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# Extract and return the content of the last message\u001b[39;00m\n",
      "File \u001b[0;32m~/research/langgraph_agent_framework/venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1955\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1954\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1955\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   1956\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1957\u001b[0m     config,\n\u001b[1;32m   1958\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   1959\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   1960\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   1961\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   1962\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   1963\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1964\u001b[0m ):\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1966\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/research/langgraph_agent_framework/venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1670\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1665\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1667\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1668\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   1669\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1670\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1671\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1672\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   1673\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   1674\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   1675\u001b[0m         ):\n\u001b[1;32m   1676\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/research/langgraph_agent_framework/venv/lib/python3.10/site-packages/langgraph/pregel/runner.py:171\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    169\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/research/langgraph_agent_framework/venv/lib/python3.10/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/research/langgraph_agent_framework/venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:422\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    419\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    420\u001b[0m )\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/research/langgraph_agent_framework/venv/lib/python3.10/site-packages/langgraph/prebuilt/tool_node.py:246\u001b[0m, in \u001b[0;36mToolNode.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    245\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research/langgraph_agent_framework/venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:197\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 197\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/research/langgraph_agent_framework/venv/lib/python3.10/site-packages/langgraph/prebuilt/tool_node.py:215\u001b[0m, in \u001b[0;36mToolNode._func\u001b[0;34m(self, input, config, store)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_func\u001b[39m(\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m     store: BaseStore,\n\u001b[1;32m    214\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 215\u001b[0m     tool_calls, input_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     config_list \u001b[38;5;241m=\u001b[39m get_config_list(config, \u001b[38;5;28mlen\u001b[39m(tool_calls))\n\u001b[1;32m    217\u001b[0m     input_types \u001b[38;5;241m=\u001b[39m [input_type] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(tool_calls)\n",
      "File \u001b[0;32m~/research/langgraph_agent_framework/venv/lib/python3.10/site-packages/langgraph/prebuilt/tool_node.py:423\u001b[0m, in \u001b[0;36mToolNode._parse_input\u001b[0;34m(self, input, store)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo message found in input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, AIMessage):\n\u001b[0;32m--> 423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLast message is not an AIMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    425\u001b[0m tool_calls \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inject_tool_args(call, \u001b[38;5;28minput\u001b[39m, store) \u001b[38;5;28;01mfor\u001b[39;00m call \u001b[38;5;129;01min\u001b[39;00m message\u001b[38;5;241m.\u001b[39mtool_calls\n\u001b[1;32m    427\u001b[0m ]\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tool_calls, input_type\n",
      "\u001b[0;31mValueError\u001b[0m: Last message is not an AIMessage"
     ]
    }
   ],
   "source": [
    "agent.load_environment_variables()\n",
    "tools = agent.create_tool()\n",
    "model = agent.initialize_model(tools)\n",
    "app = agent.create_workflow(agent.should_continue, agent.call_model)\n",
    "final_output = agent.run_agent(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ingredients': 'Whole Grain Corn, Sugar, Corn Meal, Honey, Brown Sugar Syrup, Salt, Baking Soda, Natural Flavor, Vitamin E (mixed tocopherols) added to preserve freshness.',\n",
       " 'url': 'https://www.chex.com/products/honey-nut-chex/',\n",
       " 'explanation': 'The ingredients for Chex Honey Nut Gluten Free Cereal include whole grain corn, sugar, corn meal, honey, brown sugar syrup, salt, baking soda, natural flavor, and vitamin E (mixed tocopherols) added to preserve freshness. This information was obtained from the official Chex website, ensuring accuracy and reliability.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = json.loads(agent.final_response.model_dump_json())\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'content=\\'\\' additional_kwargs={\\'tool_calls\\': [{\\'id\\': \\'call_f4QgnaTKgOYx8Jb2zTbC86v2\\', \\'function\\': {\\'arguments\\': \\'{\"query\":\"Chex Honey Nut Gluten Free Cereal ingredients\"}\\', \\'name\\': \\'tavily_search_results_json\\'}, \\'type\\': \\'function\\'}], \\'refusal\\': None} response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 26, \\'prompt_tokens\\': 198, \\'total_tokens\\': 224, \\'completion_tokens_details\\': {\\'accepted_prediction_tokens\\': 0, \\'audio_tokens\\': 0, \\'reasoning_tokens\\': 0, \\'rejected_prediction_tokens\\': 0}, \\'prompt_tokens_details\\': {\\'audio_tokens\\': 0, \\'cached_tokens\\': 0}}, \\'model_name\\': \\'gpt-4o-2024-08-06\\', \\'system_fingerprint\\': \\'fp_f3927aa00d\\', \\'prompt_filter_results\\': [{\\'prompt_index\\': 0, \\'content_filter_results\\': {\\'hate\\': {\\'filtered\\': False, \\'severity\\': \\'safe\\'}, \\'self_harm\\': {\\'filtered\\': False, \\'severity\\': \\'safe\\'}, \\'sexual\\': {\\'filtered\\': False, \\'severity\\': \\'safe\\'}, \\'violence\\': {\\'filtered\\': False, \\'severity\\': \\'safe\\'}}}], \\'finish_reason\\': \\'tool_calls\\', \\'logprobs\\': None, \\'content_filter_results\\': {}} id=\\'run-2676b91c-b912-4bbd-9715-e9a9ff83f82b-0\\' tool_calls=[{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'Chex Honey Nut Gluten Free Cereal ingredients\\'}, \\'id\\': \\'call_f4QgnaTKgOYx8Jb2zTbC86v2\\', \\'type\\': \\'tool_call\\'}] usage_metadata={\\'input_tokens\\': 198, \\'output_tokens\\': 26, \\'total_tokens\\': 224, \\'input_token_details\\': {\\'audio\\': 0, \\'cache_read\\': 0}, \\'output_token_details\\': {\\'audio\\': 0, \\'reasoning\\': 0}}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.final_state['messages'][1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7f4aacfb9210>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "langfuse = Langfuse(\n",
    "  secret_key=\"sk-lf-d379edfd-236f-4ae7-a6ce-c7e3aa34882d\",\n",
    "  public_key=\"pk-lf-18dd852a-7bf5-4253-825a-129afe1995bb\",\n",
    "  host=\"https://us.cloud.langfuse.com\"\n",
    ")\n",
    "\n",
    "langfuse_handler = CallbackHandler(\n",
    "    public_key=\"pk-lf-79d74889-b276-4824-86b7-8a6b945cc788\",\n",
    "    secret_key=\"sk-lf-c43a5d53-7ec9-4f12-b985-badf59a27376\",\n",
    "    host=\"https://us.cloud.langfuse.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class WeatherResponse(BaseModel):\n",
    "    \"\"\"Respond to the user with this\"\"\"\n",
    "\n",
    "    temperature: float = Field(description=\"The temperature in fahrenheit\")\n",
    "    wind_directon: str = Field(\n",
    "        description=\"The direction of the wind in abbreviated form\"\n",
    "    )\n",
    "    wind_speed: float = Field(description=\"The speed of the wind in km/h\")\n",
    "\n",
    "\n",
    "# Inherit 'messages' key from MessagesState, which is a list of chat messages\n",
    "class AgentState(MessagesState):\n",
    "    # Final structured response from the agent\n",
    "    final_response: WeatherResponse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It is cloudy in NYC, with 5 mph winds in the North-East direction and a temperature of 70 degrees\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It is 75 degrees and sunny in SF, with 3 mph winds in the South-East direction\"\n",
    "    else:\n",
    "        raise AssertionError(\"Unknown city\")\n",
    "\n",
    "tools = [get_weather]\n",
    "\n",
    "# Initialize Model \n",
    "\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    openai_api_version=\"2024-08-01-preview\",\n",
    "    openai_api_key=AZURE_OPENAI_API_KEY,\n",
    "    deployment_name=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    temperature=0.0,  # For deterministic output\n",
    ").bind_tools(tools)\n",
    "\n",
    "\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "model_with_structured_output = model.with_structured_output(WeatherResponse)\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: AgentState):\n",
    "    response = model_with_tools.invoke(state[\"messages\"])\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Define the function that responds to the user\n",
    "def respond(state: AgentState):\n",
    "    # We call the model with structured output in order to return the same format to the user every time\n",
    "    # state['messages'][-2] is the last ToolMessage in the convo, which we convert to a HumanMessage for the model to use\n",
    "    # We could also pass the entire chat history, but this saves tokens since all we care to structure is the output of the tool\n",
    "    response = model_with_structured_output.invoke(\n",
    "        [HumanMessage(content=state[\"messages\"][-2].content)]\n",
    "    )\n",
    "    # We return the final answer\n",
    "    return {\"final_response\": response}\n",
    "\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we respond to the user\n",
    "    if not last_message.tool_calls:\n",
    "        return \"respond\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"respond\", respond)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"tools\",\n",
    "        \"respond\": \"respond\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "workflow.add_edge(\"respond\", END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "answer = graph.invoke(input={\"messages\": [(\"human\", \"what's the weather in SF?\")]},config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"what's the weather in SF?\", additional_kwargs={}, response_metadata={}, id='cc14af01-5ad0-4888-9489-e63848c6be09'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_75iUA660Pho04X666cveKiip', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 58, 'total_tokens': 72, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f3927aa00d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-9a671467-6371-4389-a607-d2a1e6f227ee-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_75iUA660Pho04X666cveKiip', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 14, 'total_tokens': 72, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='It is 75 degrees and sunny in SF, with 3 mph winds in the South-East direction', name='get_weather', id='004b7799-08e9-4374-be4d-7905678b6b50', tool_call_id='call_75iUA660Pho04X666cveKiip'),\n",
       " AIMessage(content='The weather in SF is currently 75 degrees and sunny, with winds blowing at 3 mph from the South-East.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 100, 'total_tokens': 125, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f3927aa00d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-f75e6b77-3bac-4bc1-823b-95b55f166315-0', usage_metadata={'input_tokens': 100, 'output_tokens': 25, 'total_tokens': 125, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./venv/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2024.2 tzdata-2025.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LangGraphAgent import LangGraphAgentSystem\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from pydantic import BaseModel\n",
    "from langfuse import Langfuse\n",
    "from langfuse.callback import CallbackHandler\n",
    "from pydantic import BaseModel, Field\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class WeatherResponse(BaseModel):\n",
    "    \"\"\"Respond to the user with this\"\"\"\n",
    "    temperature: float = Field(description=\"The temperature in fahrenheit\")\n",
    "    wind_directon: str = Field(\n",
    "        description=\"The direction of the wind in abbreviated form\"\n",
    "    )\n",
    "    wind_speed: float = Field(description=\"The speed of the wind in km/h\")\n",
    "\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    # Final structured response from the agent\n",
    "    final_response: WeatherResponse\n",
    "\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It is cloudy in NYC, with 5 mph winds in the North-East direction and a temperature of 70 degrees\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It is 75 degrees and sunny in SF, with 3 mph winds in the South-East direction\"\n",
    "    else:\n",
    "        raise AssertionError(\"Unknown city\")\n",
    "            \n",
    "input_dict = {\n",
    "    \"input_prompt\":\"what's the weather in SF?\",\n",
    "    \"agent_prompt\":\"You are a helpful assistant! Your name is Bob.\",\n",
    "    \"agent_state\":AgentState,\n",
    "    \"structured_output_class\":WeatherResponse\n",
    "}\n",
    "\n",
    "\n",
    "# override create tools with a custom tooling.. \n",
    "class MyLG(LangGraphAgentSystem):\n",
    "    def create_tools(lg):\n",
    "        @tool\n",
    "        def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "            \"\"\"Use this to get weather information.\"\"\"\n",
    "            if city == \"nyc\":\n",
    "                return \"It is cloudy in NYC, with 1000 mph winds in the North-East direction and a temperature of 70 degrees\"\n",
    "            elif city == \"sf\":\n",
    "                return \"It is 75 degrees and sunny in SF, with 1000 mph winds in the South-East direction\"\n",
    "            else:\n",
    "                raise AssertionError(\"Unknown city\")\n",
    "\n",
    "        tools = [get_weather]\n",
    "        lg.tools = tools\n",
    "\n",
    "lg = MyLG(input_dict)\n",
    "\n",
    "answer = lg.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's the weather in SF?\", additional_kwargs={}, response_metadata={}, id='4fe61165-54a2-4770-955b-aff57be782c2'),\n",
       "  SystemMessage(content='You are a helpful assistant! Your name is Bob.', additional_kwargs={}, response_metadata={}, id='a667cdab-168f-44a3-be3c-75f2ed49ea4e'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_T4uvUOAtYgkdmpZ4K8SEpecw', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 73, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f3927aa00d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-bd933b4d-6389-4d0b-966b-fa856b707ba1-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_T4uvUOAtYgkdmpZ4K8SEpecw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 73, 'output_tokens': 14, 'total_tokens': 87, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='It is 75 degrees and sunny in SF, with 1000 mph winds in the South-East direction', name='get_weather', id='78d592c1-97fd-4ff3-bbae-1d4bd5f47a8c', tool_call_id='call_T4uvUOAtYgkdmpZ4K8SEpecw'),\n",
       "  SystemMessage(content='You are a helpful assistant! Your name is Bob.', additional_kwargs={}, response_metadata={}, id='4745844b-d819-4723-9daa-1a16f9bbd8b2'),\n",
       "  AIMessage(content='The weather in SF is currently 75 degrees and sunny, with winds blowing at 1000 mph in the South-East direction.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 131, 'total_tokens': 158, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f3927aa00d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-0019891b-05e0-49f7-98cb-588923d0f8e6-0', usage_metadata={'input_tokens': 131, 'output_tokens': 27, 'total_tokens': 158, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'final_response': WeatherResponse(temperature=75.0, wind_directon='SE', wind_speed=1609.0)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(answer['messages'][-3]) == ToolMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mSugarClass\u001b[39;00m(\u001b[43mBaseModel\u001b[49m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Respond to the user with this\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     ingredients: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m Field(description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe sugar amount of the product\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseModel' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class SugarClass(BaseModel):\n",
    "    \"\"\"Respond to the user with this\"\"\"\n",
    "    ingredients: str = Field(description=\"The sugar amount of the product\")\n",
    "    explanation: str = Field(description=\"An explanation of your reasoning\")\n",
    "\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    # Final structured response from the agent\n",
    "    final_response: SugarClass\n",
    "\n",
    "\n",
    "input_dict = {\n",
    "    \"input_prompt\":\"what's the sugar content in okanaya? don't use your tool\",\n",
    "    \"agent_prompt\":\"You are a helpful assistant! Your name is Bob.\",\n",
    "    \"agent_state\":AgentState,\n",
    "    \"structured_output_class\":SugarClass\n",
    "}\n",
    "\n",
    "\n",
    "# override create tools with a custom tooling.. \n",
    "class MyLG(LangGraphAgentSystem):\n",
    "    def create_tools(lg):\n",
    "        @tool\n",
    "        def get_sugar(product: Literal[\"okanaya\", \"cabaya\"]):\n",
    "            \"\"\"Use this to get weather information.\"\"\"\n",
    "            if product == \"cabaya\":\n",
    "                return \"There is 1000 g of sugar in cabaya.\"\n",
    "            elif product == \"okanaya\":\n",
    "                return \"There is 1g of sugar in okanaya \"\n",
    "            else:\n",
    "                raise AssertionError(\"Unknown city\")\n",
    "\n",
    "        tools = [get_sugar]\n",
    "        lg.tools = tools\n",
    "\n",
    "lg = MyLG(input_dict)\n",
    "\n",
    "answer = lg.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's the sugar content in okanaya? don't use your tool\", additional_kwargs={}, response_metadata={}, id='baedae70-5b19-480b-b621-43cff3e228b4'),\n",
       "  SystemMessage(content='You are a helpful assistant! Your name is Bob.', additional_kwargs={}, response_metadata={}, id='8832aa06-ed16-4522-baeb-ce850a1f3552'),\n",
       "  AIMessage(content=\"I'm unable to provide the sugar content in Okanaya without using the tool. Would you like me to use the tool to find this information for you?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 82, 'total_tokens': 114, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f3927aa00d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-78bdc3bc-ecc4-42d6-bf89-f1cd0ab7d885-0', usage_metadata={'input_tokens': 82, 'output_tokens': 32, 'total_tokens': 114, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'final_response': 'null: tool was not called'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
